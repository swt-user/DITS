{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59df36b7-19ff-4987-93e3-e3ab4f8fa25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wentaos/Optima/local_influence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613400b2-4754-495c-91ae-eb280a9899f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"/home/wentaos/Optima/local_influence/recipe/hotpotqa/iteration_0_dpo.yaml\", \"r\") as config_f:\n",
    "    config = yaml.safe_load(config_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992f4df7-7195-4933-920c-c0d12bf9c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b421d8e1-a080-4eeb-ba29-e18b8d3080ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wentaos/miniconda3/envs/trak/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/wentaos/miniconda3/envs/trak/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from accelerate import Accelerator\n",
    "from datasets import Dataset, load_from_disk\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "import transformers\n",
    "# from utils import PartialMaskTokenizer, reformat_to_chat\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from my_utils import (get_tokenizer, process_dpo_format_to_dataset, \n",
    "        apply_chat_template, decontaminate_humaneval, dpo_generate_and_tokenize_prompt, \n",
    "        SFT_generate_and_tokenize_prompt, PreferenceCollator, DataArguments, get_datasets)\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b7af60-e8e0-40c5-a908-16e9eeb25b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime: 2024-11-13 18:18:38\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "os.environ[\"HF_HOME\"]=\"~/.cache/huggingface\"\n",
    "\n",
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "accelerator.print(\n",
    "    f\"datetime: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", flush=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e451472-17e2-4779-a0c8-dab8a0117c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b3cbbf72954ebc8576560f0d2aaba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.first adapter.weight\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.first adapter.weight\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(config[\"lora_path\"])\n",
    "# peft_config.base_model_name_or_path = config[\"model_name_or_path\"]\n",
    "\n",
    "\n",
    "\n",
    "raw_model = LlamaForCausalLM.from_pretrained(config[\"model_name_or_path\"], \n",
    "                                            torch_dtype=torch.float16,\n",
    "                                            device_map=\"cuda\",\n",
    "                                            cache_dir=os.environ[\"HF_HOME\"],\n",
    "                                            )\n",
    "raw_model = PeftModel.from_pretrained(raw_model, config[\"lora_path\"], torch_dtype=torch.float16, adapter_name=\"first adapter\")\n",
    "for n, p in raw_model.named_parameters():\n",
    "    if 'lora' in n:\n",
    "        print(n)\n",
    "        p.requires_grad = True\n",
    "# raw_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     config[\"model_name_or_path\"],\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"cpu\",\n",
    "#     cache_dir=os.environ[\"HF_HOME\"],\n",
    "# )\n",
    "model = accelerator.prepare(raw_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfa6b54-b5cf-4ffa-aa3b-5ed4617e9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collect import get_dpo_dataloader\n",
    "tokenizer = get_tokenizer(config[\"tokenizer_path\"], truncation_side=\"left\") \n",
    "\n",
    "train_args, eval_args, tokenizer_path = (\n",
    "    config[\"train_args\"],\n",
    "    config[\"eval_args\"],\n",
    "    config[\"tokenizer_path\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d74bfb-7ea9-429e-89f1-32d8ed7b99f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/14679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decontaminating HumanEval samples:   0%|          | 0/14679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decontaminating HumanEval samples:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train dataset:DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 14679\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 1632\n",
      "    })\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = get_dpo_dataloader(accelerator, train_args, \"train\", tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deed14d5-08da-4bfc-938b-a3b9b0708037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/14025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting comparisons with prompt template:   0%|          | 0/1559 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decontaminating HumanEval samples:   0%|          | 0/14025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decontaminating HumanEval samples:   0%|          | 0/1559 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1559 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train dataset:DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 14025\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 1559\n",
      "    })\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = get_dpo_dataloader(accelerator, eval_args, \"test\", tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa9f556-628c-4dc5-803a-1848943625da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collect import get_sft_dataloader\n",
    "# eval_dataloader = get_sft_dataloader(accelerator, eval_args, \"test\", tokenizer)\n",
    "\n",
    "optimizer = AdamW(params=model.parameters())\n",
    "\n",
    "optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    optimizer, train_dataloader, eval_dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c275e4ff-5a0d-4dcb-8079-5014015085b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import pad_to_length\n",
    "import torch.nn.functional as F\n",
    "from torch.func import functional_call, vmap\n",
    "max_completion_length = 1024\n",
    "if \"llama-3\":\n",
    "    padding_value = 128002\n",
    "    \n",
    "def compute_dpo_loss(model, prompt_input_ids, prompt_attention_mask, chosen_input_ids, chosen_attention_mask, rejected_input_ids, rejected_attention_mask):\n",
    "\n",
    "    rpo_alpha = 1.0\n",
    "    beta = 0.1\n",
    "    max_length = 1024\n",
    "\n",
    "    \n",
    "    \n",
    "    num_examples = prompt_input_ids.shape[0]\n",
    "   \n",
    "    \n",
    "    # For the prompt, the input_ids are the same for both the chosen and rejected responses\n",
    "    prompt_input_ids = torch.cat([prompt_input_ids, prompt_input_ids], dim=0)\n",
    "    prompt_attention_mask = torch.cat(\n",
    "        [prompt_attention_mask, prompt_attention_mask], dim=0\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # Concatenate the chosen and rejected completions\n",
    "    max_completion_length = max(chosen_input_ids.shape[1], rejected_input_ids.shape[1])\n",
    "    completion_input_ids = torch.cat(\n",
    "        (\n",
    "            pad_to_length(chosen_input_ids, max_completion_length, pad_value=padding_value),\n",
    "            pad_to_length(rejected_input_ids, max_completion_length, pad_value=padding_value),\n",
    "        ),\n",
    "    )\n",
    "    completion_attention_mask = torch.cat(\n",
    "        (\n",
    "            pad_to_length(chosen_attention_mask, max_completion_length, pad_value=0),\n",
    "            pad_to_length(rejected_attention_mask, max_completion_length, pad_value=0),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    \n",
    "    input_ids = torch.cat((prompt_input_ids, completion_input_ids), dim=1)\n",
    "    attention_mask = torch.cat((prompt_attention_mask, completion_attention_mask), dim=1)\n",
    "    # Mask the prompt but not the completion for the loss\n",
    "    loss_mask = torch.cat(\n",
    "        (torch.zeros_like(prompt_attention_mask), completion_attention_mask),\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    if max_length is not None:\n",
    "        input_ids = input_ids[:, : max_length]\n",
    "        attention_mask = attention_mask[:, : max_length]\n",
    "        loss_mask = loss_mask[:, : max_length]\n",
    "    # # Flush left to reduce the memory usage\n",
    "    # # [[0, 0, x, x, x, x],  ->  [[x, x, x, x],\n",
    "    # #  [0, x, x, x, 0, 0]]       [x, x, x, 0]]\n",
    "    # for i in range(attention_mask.size(0)):\n",
    "    #     first_one_idx = torch.nonzero(attention_mask[i])[0].item()\n",
    "    #     input_ids[i] = torch.roll(input_ids[i], shifts=-first_one_idx)\n",
    "    #     attention_mask[i] = torch.roll(attention_mask[i], shifts=-first_one_idx)\n",
    "    #     loss_mask[i] = torch.roll(loss_mask[i], shifts=-first_one_idx)\n",
    "\n",
    "    # # Get the first column idx that is all zeros and remove every column after that\n",
    "    # empty_cols = torch.sum(attention_mask, dim=0) == 0\n",
    "    # first_empty_col = torch.nonzero(empty_cols)[0].item() if empty_cols.any() else attention_mask.size(1)\n",
    "    # input_ids = input_ids[:, :first_empty_col]\n",
    "    # attention_mask = attention_mask[:, :first_empty_col]\n",
    "    # loss_mask = loss_mask[:, :first_empty_col]\n",
    "\n",
    "    labels = input_ids[:, 1:].clone()\n",
    "    loss_mask = loss_mask[:, 1:].bool()\n",
    "    # labels[~loss_mask] = 0\n",
    "    labels = torch.where(loss_mask, labels, torch.tensor(0, dtype=labels.dtype, device=labels.device))\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, \n",
    "                                  kwargs={'attention_mask': attention_mask, \n",
    "                                          # 'labels': labels\n",
    "                                         })\n",
    "    \n",
    "    \n",
    "    logits = outputs.logits[:, :-1, :]\n",
    "    per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n",
    "    # per_token_logps[~loss_mask] = 0\n",
    "    per_token_logps = torch.where(loss_mask, per_token_logps, torch.tensor(0, dtype=per_token_logps.dtype, device=per_token_logps.device))\n",
    "    all_logps = per_token_logps.sum(-1)\n",
    "    chosen_logps = all_logps[:num_examples]\n",
    "    rejected_logps = all_logps[num_examples:]\n",
    "\n",
    "    \n",
    "        \n",
    "    if rpo_alpha is not None:\n",
    "        chosen_logits = logits[:num_examples]\n",
    "        chosen_labels = labels[:num_examples]\n",
    "\n",
    "        # Compute the log probabilities of the labels\n",
    "        nll_loss = F.cross_entropy(\n",
    "            torch.flatten(chosen_logits, end_dim=1), torch.flatten(chosen_labels, end_dim=1), ignore_index=0\n",
    "        )\n",
    "\n",
    "    with model.disable_adapter():\n",
    "        \n",
    "        ref_outputs = model(input_ids=input_ids, \n",
    "                                  kwargs={'attention_mask': attention_mask, \n",
    "                                          # 'labels': labels\n",
    "                                         })\n",
    "        ref_logits = ref_outputs.logits[:, :-1, :]\n",
    "        ref_per_token_logps = torch.gather(ref_logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n",
    "        # ref_per_token_logps[~loss_mask] = 0\n",
    "        ref_per_token_logps = torch.where(loss_mask, ref_per_token_logps, torch.tensor(0, dtype=ref_per_token_logps.dtype, device=ref_per_token_logps.device))\n",
    "        ref_all_logps = ref_per_token_logps.sum(-1)\n",
    "        ref_chosen_logps = ref_all_logps[:num_examples]\n",
    "        ref_rejected_logps = ref_all_logps[num_examples:]\n",
    "\n",
    "\n",
    "    \n",
    "    pi_logratios = chosen_logps - rejected_logps\n",
    "    ref_logratios = ref_chosen_logps - ref_rejected_logps\n",
    "    differences = pi_logratios - ref_logratios\n",
    "    losses = -F.logsigmoid(beta * differences)\n",
    "    \n",
    "    loss = losses + rpo_alpha * nll_loss\n",
    "    \n",
    "    # print(loss)\n",
    "    return loss.squeeze(0) # must be a scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f567d297-4cec-4cfc-ada5-f539311623ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 13 18:21:06 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:87:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             68W /  380W |   16159MiB /  40960MiB |      3%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2869407      C   ...aos/miniconda3/envs/trak/bin/python      16150MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db482de5-503b-4d0b-9d0b-d52672e4542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_train(\n",
    "    model: AutoModelForCausalLM,\n",
    "    optimizer: AdamW,\n",
    "    accelerator: Accelerator,\n",
    "    data_batch: Dict[str, torch.Tensor],\n",
    "    eval_dataloader: DataLoader,\n",
    "    step: int,\n",
    "    avg_loss_before: float,\n",
    ") -> float:\n",
    "    device = \"cpu\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    data_batch = {k: v.to(device) for k, v in data_batch.items()}\n",
    "    loss = compute_dpo_loss(model, data_batch['prompt_input_ids'], data_batch['prompt_attention_mask'], \n",
    "                                data_batch['chosen_input_ids'], data_batch['chosen_attention_mask'],\n",
    "                                data_batch['rejected_input_ids'], data_batch['rejected_attention_mask'])\n",
    "    \n",
    "    loss = loss / accelerator.num_processes\n",
    "    # if accelerator.is_local_main_process:\n",
    "    #     print(f\"{accelerator.device} loss: {loss:.10f}\")\n",
    "    # accelerator.print(\"train loss: \", loss.item())\n",
    "    # print(f\"train loss {loss.item()} on device {accelerator.device}\")\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # eval\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for index, batch in tqdm(\n",
    "        enumerate(eval_dataloader),\n",
    "        total=len(eval_dataloader),\n",
    "        desc=\"Evaluating\",\n",
    "        disable=not accelerator.is_local_main_process,\n",
    "    ):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            loss = compute_dpo_loss(model, batch['prompt_input_ids'], batch['prompt_attention_mask'], \n",
    "                                                        batch['chosen_input_ids'], batch['chosen_attention_mask'],\n",
    "                                                        batch['rejected_input_ids'], batch['rejected_attention_mask'])\n",
    "            \n",
    "        loss_withoutnan = torch.nanmean(accelerator.gather(loss))\n",
    "        total_loss += loss_withoutnan.item()\n",
    "    avg_loss_after = total_loss / len(eval_dataloader)\n",
    "    accelerator.print(f\"eval loss after one step train: {avg_loss_after}\")\n",
    "    accelerator.print(f\"eval loss diff: {avg_loss_after - avg_loss_before}\")\n",
    "    return avg_loss_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfa4c9-7c76-4e82-9ef8-eeaf5b538033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                              | 0/1632 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........train batch: 0...........\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtain baseline reference loss\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "device = \"cuda\"\n",
    "    \n",
    "\n",
    "\n",
    "# for index, batch in tqdm(\n",
    "#     enumerate(eval_dataloader),\n",
    "#     total=len(eval_dataloader),\n",
    "#     desc=\"Evaluating\",\n",
    "#     disable=not accelerator.is_local_main_process,\n",
    "# ):\n",
    "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         loss = compute_dpo_loss(model, batch['prompt_input_ids'], batch['prompt_attention_mask'], \n",
    "#                                                      batch['chosen_input_ids'], batch['chosen_attention_mask'],\n",
    "#                                                      batch['rejected_input_ids'], batch['rejected_attention_mask'])\n",
    "#         # print(loss)\n",
    "#     # loss = outputs.loss\n",
    "#     loss_withoutnan = torch.nanmean(accelerator.gather(loss))\n",
    "#     loss = accelerator.gather(loss).mean()\n",
    "#     # print(loss)\n",
    "#     # print(loss_withoutnan)\n",
    "#     total_loss += loss_withoutnan.item()\n",
    "# avg_loss_before = total_loss / len(eval_dataloader)\n",
    "# accelerator.print(f\"baseline reference loss: {avg_loss_before}\")\n",
    "# # Write the baseline reference loss to a file\n",
    "# baseline_ref_loss_path = os.path.join(\n",
    "#     Path(config[\"train_args\"][\"data_path\"]).parent, \"baseline_ref_loss.txt\"\n",
    "# )\n",
    "# print(f\"baseline reference loss path: {baseline_ref_loss_path}\")\n",
    "# with open(baseline_ref_loss_path, \"w\") as f:\n",
    "#     f.write(f\"{avg_loss_before}\")\n",
    "avg_loss_before = 0\n",
    "\n",
    "score_list = []\n",
    "for step, batch in tqdm(\n",
    "    enumerate(train_dataloader),\n",
    "    total=len(train_dataloader),\n",
    "    desc=\"Training\",\n",
    "    disable=not accelerator.is_local_main_process,\n",
    "):\n",
    "    accelerator.print(f\"..........train batch: {step}...........\")\n",
    "    t1 = datetime.now()\n",
    "    loss = one_step_train(\n",
    "        model, optimizer, accelerator, batch, eval_dataloader, step, avg_loss_before\n",
    "    )\n",
    "    # accelerator.print(\n",
    "    #     f\"Epoch {epoch}, Step {step}, Loss on {accelerator.device}: {loss}\"\n",
    "    # )\n",
    "    score_list.append(loss)\n",
    "    # accelerator.load_state(config[\"warm_up_path\"])\n",
    "    t2 = datetime.now()\n",
    "    accelerator.print(f\"time taken: {(t2 - t1).total_seconds()}\")\n",
    "# print(score_list)\n",
    "# raw_train_dataset = raw_train_dataset.add_column(\"scores\", score_list)\n",
    "# raw_train_dataset.save_to_disk(config[\"scores_dataset_path\"])\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013f241-a5a9-4104-adb0-f1c294bbd317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181eecc4-5f36-43e1-a848-cd4b5d84389f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d259bff-b3ce-4f85-b127-cc342b6254c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
